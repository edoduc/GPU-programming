{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cweMlOB0L4mG"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IA704 - Linear Classification Lab\n",
        "## Edouard Ducloy"
      ],
      "metadata": {
        "id": "WiypDMbcJorg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ewR7_sHJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68e3684-3925-4bc5-ab1a-60f903fc2f4c"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download repository with helper_cuda.h:"
      ],
      "metadata": {
        "id": "neVqpQNceYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ase9AQyweUSJ",
        "outputId": "154aa32d-8a46-4918-ad10-3b4f72406e87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 18274, done.\u001b[K\n",
            "remote: Counting objects: 100% (3689/3689), done.\u001b[K\n",
            "remote: Compressing objects: 100% (576/576), done.\u001b[K\n",
            "remote: Total 18274 (delta 3346), reused 3150 (delta 3113), pack-reused 14585\u001b[K\n",
            "Receiving objects: 100% (18274/18274), 133.19 MiB | 12.70 MiB/s, done.\n",
            "Resolving deltas: 100% (16006/16006), done.\n",
            "Updating files: 100% (3998/3998), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIyq5vPjxKc"
      },
      "source": [
        "Based on the lecture at https://sites.google.com/site/frehseg/teaching/ia307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Provided Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lgwhE1N5_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9137aee0-b220-485a-eafb-80c1603a151e"
      },
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivrxLaYOYPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcba4266-e0df-4703-a0f9-ec0efc65beb0"
      },
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## fmatrix Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A97U902HMog4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684b2fee-b4fa-48f0-d4b3-180d9929b95c"
      },
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "////////////////////////////////////////\n",
        "// basic data structure and access macro\n",
        "////////////////////////////////////////\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/** Access element (i,j) of matrix M\n",
        " *\n",
        " *  Usage example:\n",
        " *  For computing A = B^T + C), loop over i and j with:\n",
        " *    getfm(A,i,j) = getfm(B,j,i) + getfm(C,i,j);\n",
        " **/\n",
        "#define getfm(M,i,j) (M.data[IDX2C(i,j,M.rows)])\n",
        "\n",
        "////////////////////////////////////////\n",
        "// utility functions\n",
        "////////////////////////////////////////\n",
        "/** Returns the number of elements in the matrix.\n",
        " *\n",
        " *  Useful for computing, e.g., the size\n",
        " *  of a 1D-vector that contains the same numbers.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "\n",
        "/** Returns the memory occupied by the matrix elements in bytes\n",
        " *  (not including the variables in the struct mat).\n",
        " *\n",
        " *  Useful for allocating memory for the data.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_size(fmatrix mat);\n",
        "\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_assert(fmatrix mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Create, copy, destroy\n",
        "////////////////////////////////////////\n",
        "/** Allocate memory on host */\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "\n",
        "/** Allocate memory on device */\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M.\n",
        " *  Note that the new matrix uses a pointer to the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " *  If M is destroyed, this matrix is useless.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Copy data from matrix on device to host\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy data from matrix on host to device\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from device to host, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from host to device, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "\n",
        "/** Free data memory on host.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "\n",
        "/** Free data memory on device.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Input and Output\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host.\n",
        " *  If nb<0, print all rows.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print a matrix to a csv file.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat);\n",
        "\n",
        "/** Read a matrix from a csv file.\n",
        " *\n",
        " *  This version creates the matrix on the host first.\n",
        " */\n",
        "fmatrix fmatrix_device_from_csv(const char* filename);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Useful\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Create a matrix with random values between -1 and 1\n",
        " *  on the device */\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols);\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGwZ36ifWQ-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccc9efb-8791-449c-d0bc-d20ab5cde062"
      },
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "// for reading CSV files, we use some C++\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "//    fmatrix_assert(mat);\n",
        "     return fmatrix_elements(mat) * sizeof(float);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat));\n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk(\n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat))\n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_device.data, mat_host.data,\n",
        "                   fmatrix_size(mat_host),\n",
        "                   cudaMemcpyHostToDevice\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,\n",
        "                   fmatrix_size(mat_device),\n",
        "                   cudaMemcpyDeviceToHost\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "/** We could do it like this, but it would not set our pointer M.data to 0.\n",
        "... fmatrix_free_on_host(M)\n",
        "void fmatrix_free_on_host(fmatrix mat) {\n",
        "    fmatrix_assert(mat);\n",
        "  free(mat.data);\n",
        "  mat.data = 0;\n",
        "  mat.cols = 0;\n",
        "  mat.rows = 0;\n",
        "}\n",
        "*/\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);\n",
        "    fmatrix A = {\n",
        "        .data = &getfm(M,0,a),\n",
        "        .cols = b-a,\n",
        "        .rows = M.rows\n",
        "    };\n",
        "    fmatrix_assert(A);\n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat) {\n",
        "  // Open file\n",
        "  FILE* fp = fopen(filename, \"w\");\n",
        "  // allocate copy\n",
        "  fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "  for (int i = 0 ; i < tmp.rows; i++){\n",
        "    for (int j = 0 ; j<tmp.cols; j++){\n",
        "      // Note: %.15g gives 15 significant digits (full double precision)\n",
        "      fprintf(fp,\"%.15g\", getfm(tmp,i,j));\n",
        "      if (j+1<tmp.cols) {\n",
        "        fprintf(fp,\",\");\n",
        "      }\n",
        "    }\n",
        "    fprintf(fp,\"\\n\");\n",
        "  }\n",
        "  fmatrix_free_on_host(&tmp);\n",
        "  // Close file\n",
        "  fclose(fp);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_create_random_on_device_kernel(fmatrix M) {\n",
        "    // choose a seed (here: the same each launch)\n",
        "    unsigned long seed = 0;\n",
        "    int sequence = 0;\n",
        "    // first, initialize the random numbers\n",
        "    curandState state;\n",
        "    curand_init(seed, sequence, 0, &state);\n",
        "    for (int i = 0; i < fmatrix_elements(M); ++i) {\n",
        "        // curand_uniform creates numbers between 0 and 1\n",
        "        M.data[i] = (curand_uniform(&state)-0.5)*2.0;\n",
        "    }\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols) {\n",
        "    // Create an uninitialized matrix on the device\n",
        "    fmatrix M = fmatrix_create_on_device(rows,cols);\n",
        "    // Call a kernel with a single thread to fill the values\n",
        "    fmatrix_create_random_on_device_kernel<<<1,1>>>(M);\n",
        "\n",
        "    return M;\n",
        "}\n",
        "\n",
        "/* Count the number of rows and columns in a csv files (without headers) */\n",
        "void count_elements_in_csv(const char* filename, int* rows, int* cols) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "\n",
        "  *rows = 0;\n",
        "  *cols = 0;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int tempcols = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "          ++tempcols;\n",
        "        }\n",
        "        if (tempcols > *cols) {\n",
        "           *cols = tempcols;\n",
        "        }\n",
        "        ++(*rows);\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "/** Read the data from a csv file into an fmatrix on the host.\n",
        " *  Careful: We assume that the matrix has the right dimensions!\n",
        " *  Use count_elements_in_csv(...) to get the dimensions if\n",
        " *  unknown.\n",
        " */\n",
        "void fmatrix_fill_from_csv(fmatrix h_M,const char* filename) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int col = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "\t\t\t\t\tgetfm(h_M,row,col) = strtod(value.c_str(), NULL);\n",
        "          ++col;\n",
        "\t\t\t\t}\n",
        "        ++row;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_device_from_csv(const char* filename) {\n",
        "  // first read the file to count the number of elements\n",
        "  int rows = 0;\n",
        "  int cols = 0;\n",
        "  count_elements_in_csv(filename,&rows,&cols);\n",
        "\n",
        "  // allocate the matrix on the host\n",
        "  fmatrix h_M = fmatrix_create_on_host(rows,cols);\n",
        "\n",
        "  // read the data into the host matrix\n",
        "  fmatrix_fill_from_csv(h_M,filename);\n",
        "\n",
        "  // copy the matrix to the device\n",
        "  fmatrix M = fmatrix_copy_to_device(h_M);\n",
        "\n",
        "  // destroy the host matrix\n",
        "  fmatrix_free_on_host(&h_M);\n",
        "\n",
        "  return M;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKLTK8ELOdN"
      },
      "source": [
        "## Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD7rmOBmWfsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f116054f-5922-44a4-f81b-872c7270a56d"
      },
      "source": [
        "%%writefile read_csv.cuh\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef read_csv_H\n",
        "#define read_csv_H\n",
        "\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol);\n",
        "\n",
        "#endif"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing read_csv.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeedFsZ_WQx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f8e710-f2cf-48d8-9cad-67883167d2b5"
      },
      "source": [
        "%%writefile read_csv.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"cuda_stuff.cuh\" // for matrix indexing\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for reading the dataset from a file\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Read a csv file with a given number of rows and columns */\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol) {\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  double ioTemp;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row_count = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "      // read the headers (and discard)\n",
        "\t\t\tgetline(infile, row_as_string, '\\n');\n",
        "      cout << \"headers: \" << row_as_string << \"!\" << std::endl;\n",
        "      for(int i = 0; i < nbrow; i++){\n",
        "  \t\t\tgetline(infile, row_as_string, '\\n');\n",
        "        // cout << \"read line \" << row_as_string << \"!\" << std::endl;\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "\t\t\t  for(int j = 0; j < nbcol; j++){\n",
        "          getline(line_stream, value, ',');\n",
        "\t\t\t\t\tioTemp = strtod(value.c_str(), NULL);\n",
        "          // cout << \"(\"<<i<<\",\"<<j<<\") = \"<< ioTemp << std::endl;\n",
        "\n",
        "\t\t\t\t\tdata_array[IDX2C(i,j,nbrow)] = ioTemp;\n",
        "\n",
        "\t\t\t\t}\n",
        "        ++row_count;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "    cout << \"Read \" << row_count << \" rows.\" << std::endl;\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing read_csv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8ilQdYYroU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee4e0ff-c717-408e-b253-edbe890ad401"
      },
      "source": [
        "%%writefile preprocess_data.cuh\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef preprocess_data_H\n",
        "#define preprocess_data_H\n",
        "\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels );\n",
        "\n",
        "#endif"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess_data.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeUdw_KYaCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12ec054-8f95-4945-8bf3-fa1066b20275"
      },
      "source": [
        "%%writefile preprocess_data.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"preprocess_data.cuh\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   ld = number of rows\n",
        "   Example of use: a[IDX2C(0, 1, 50)] */\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for preprocessing the data set\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Split data into inputs and labels. Allocated memory for inputs and labels.\n",
        "   Since cuBLAS is column major, each input is in a column.\n",
        "   We also add 1.0 as first element to each input vector.\n",
        "*/\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels ) {\n",
        "    // The inputs are the first nbrows-1 columns.\n",
        "    // The labels are the last column (index nbrows-1), booleanized\n",
        "    // by the condition >= above_threshold\n",
        "    *input_array = (float *)malloc(nbrows * nb_inputs * sizeof(float));\n",
        "    *label_array = (float *)malloc(nbrows * nb_labels * sizeof(float));\n",
        "    //cout << &input_array << \" and \"<< &label_array << \" data \" << data_array << std::endl;\n",
        "    cout << \"Allocated memory for inputs: \" << nbrows << \" rows, \"<< nb_inputs << \" columns.\" << std::endl;\n",
        "    cout << \"Allocated memory for labels: \" << nbrows << \" rows, \"<< nb_labels << \" columns.\" << std::endl;\n",
        "\n",
        "    // Copy the data to X\n",
        "    for(int i = 0; i < nbrows; i++){\n",
        "      // Set the first element of each x to 1\n",
        "      (*input_array)[IDX2C(0,i,nb_inputs)] = 1.0;\n",
        "      // Copy the rest of x\n",
        "\t\t\tfor(int j = 1; j < nb_inputs; j++){\n",
        "\t\t\t\t(*input_array)[IDX2C(j,i,nb_inputs)] = data_array[IDX2C(i,j-1,nbrows)];\n",
        "\t\t\t}\n",
        "      float median_house_value = data_array[IDX2C(i,nbcols-1,nbrows)];\n",
        "      (*label_array)[IDX2C(0,i,nb_labels)] = 0.0;\n",
        "      (*label_array)[IDX2C(1,i,nb_labels)] = 0.0;\n",
        "      if (median_house_value >= above_threshold) {\n",
        "        (*label_array)[IDX2C(0,i,nb_labels)] = 1.0;\n",
        "      } else {\n",
        "        (*label_array)[IDX2C(1,i,nb_labels)] = 1.0;\n",
        "      }\n",
        "\t\t}\n",
        "\n",
        "    // Show some entries for double checking\n",
        "    cout << \"Inputs (first \"<<print_rows<<\"):\" << std::endl;\n",
        "\t  for(int j = 0; j < nb_inputs; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*input_array)[IDX2C(j,i,nb_inputs)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "    cout << \"Labels (first \"<<print_rows<<\"):\" << std::endl;\n",
        "    for(int j = 0; j < nb_labels; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*label_array)[IDX2C(j,i,nb_labels)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess_data.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHy3EAid05oA"
      },
      "source": [],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code That You Write"
      ],
      "metadata": {
        "id": "rR-9WFucUWLC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWS3hlAecOc"
      },
      "source": [
        "## Classifier Math"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_tmB-xbZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bccba6-548f-4a40-9610-7851d365763d"
      },
      "source": [
        "%%writefile classifier_math.cuh\n",
        "#ifndef classifier_math_H\n",
        "#define classifier_math_H\n",
        "\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "/** Returns a random float between min and max (including). */\n",
        "float float_rand( float min, float max );\n",
        "\n",
        "/** Initialize W with Xavier's method,\n",
        " *  scaled by a. */\n",
        "void xavier_weight_init(float a, fmatrix W);\n",
        "\n",
        "/** Compute the softmax for each column of Z and store in P **/\n",
        "void softmax_col(fmatrix P,fmatrix Z);\n",
        "\n",
        "///////////////////////////////////\n",
        "// TO BE COMPLETED\n",
        "// ... add your matrix math here\n",
        "///////////////////////////////////\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A = B-C */\n",
        "void fmatrix_sub(fmatrix A, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A_T = A^T */\n",
        "void transpose(fmatrix A_T, fmatrix A);\n",
        "\n",
        "/* Compute W = W-learning_rate*G */\n",
        "void fmatrix_update_weights(fmatrix W, fmatrix G, float learning_rate);\n",
        "\n",
        "/* Extract mus and sigmas from X columns */\n",
        "void extract_mean_and_stddev(fmatrix X, fmatrix means, fmatrix sigmas);\n",
        "\n",
        "/* Standardize X */\n",
        "void standardize_matrix(fmatrix X, fmatrix means, fmatrix sigmas);\n",
        "\n",
        "#endif"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier_math.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgXwgv6Bbo-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6a2603-f44f-4516-ab0c-6054abd78aa0"
      },
      "source": [
        "%%writefile classifier_math.cu\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <cfloat>\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Auxiliary function\n",
        "/////////////////////////////////////////////////////////\n",
        "// generate random numbers in interval [min,max]\n",
        "float float_rand( float min, float max )\n",
        "{\n",
        "    float scale = rand() / (float) RAND_MAX; /* [0, 1.0] */\n",
        "    return min + scale * ( max - min );      /* [min, max] */\n",
        "}\n",
        "\n",
        "void xavier_weight_init(float a, fmatrix W){\n",
        "    for (int j = 0; j < W.rows  ; ++j) {\n",
        "      for (int i = 0; i < W.cols  ; ++i) {\n",
        "          getfm(W,j,i) = a * (1.0/sqrt(W.cols+W.rows)) * float_rand(-1.0,1.0);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "//// Softmax\n",
        "\n",
        "__global__\n",
        "void softmax_kernel_device(fmatrix P, fmatrix Z) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col < P.cols) {\n",
        "        float maxVal = getfm(Z, 0, col);\n",
        "        float sum = 0.0;\n",
        "\n",
        "        // Find the max value for numerical stability\n",
        "        for (int row = 0; row < P.rows; ++row) {\n",
        "            maxVal = max(maxVal, getfm(Z, row, col));\n",
        "        }\n",
        "\n",
        "        // Compute the exponential of the difference, sum for normalization\n",
        "        for (int row = 0; row < P.rows; ++row) {\n",
        "            float val = getfm(Z, row, col);\n",
        "            float expVal = expf(val - maxVal);\n",
        "            sum += expVal;\n",
        "            getfm(P, row, col) = expVal;\n",
        "        }\n",
        "\n",
        "        // Normalize\n",
        "        for (int row = 0; row < P.rows; ++row) {\n",
        "            getfm(P, row, col) /= sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void softmax_col(fmatrix P,fmatrix Z) {\n",
        "    assert(P.cols==Z.cols);\n",
        "    assert(P.rows==Z.rows);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the softmax here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(Z);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    softmax_kernel_device<<<blocksPerGrid, threadsPerBlock>>>(P, Z);\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Multiplication de matrice\n",
        "\n",
        "__global__\n",
        "void fmatrix_multiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.cols; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,i,k)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.cols == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Multiplication de matrice avec transposé\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_tmultiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.rows; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,k,i)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.cols);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.rows == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_tmultiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Soustraction de matrice\n",
        "\n",
        "__global__\n",
        "void matrix_sub_kernel(fmatrix A, fmatrix B, fmatrix C) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = getfm(B,i,j)-getfm(C,i,j);\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = B-C */\n",
        "void fmatrix_sub(fmatrix A, fmatrix B, fmatrix C) {\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.rows == C.rows);\n",
        "    assert(A.cols == B.cols);\n",
        "    assert(A.cols == C.cols);\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    matrix_sub_kernel<<<blocksPerGrid, threadsPerBlock>>>(A,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Transposée de matrice\n",
        "\n",
        "__global__\n",
        "void transpose_kernel(fmatrix A_T, fmatrix A) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A_T,j,i) = getfm(A,i,j);\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A_T = A^T */\n",
        "void transpose(fmatrix A_T, fmatrix A) {\n",
        "    assert(A_T.rows == A.cols);\n",
        "    assert(A_T.cols == A.rows);\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    transpose_kernel<<<blocksPerGrid, threadsPerBlock>>>(A_T,A);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Modification des poids\n",
        "\n",
        "__global__\n",
        "void update_weights_kernel(fmatrix W, fmatrix G, float learning_rate) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / W.rows;\n",
        "    int i = idx % W.rows;\n",
        "    if (i < W.rows && j < W.cols ){\n",
        "        getfm(W,i,j) -= learning_rate*getfm(G,i,j);\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute W = W-learning_rate*G */\n",
        "void fmatrix_update_weights(fmatrix W, fmatrix G, float learning_rate) {\n",
        "    assert(W.rows == G.rows);\n",
        "    assert(W.cols == G.cols);\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(W);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    update_weights_kernel<<<blocksPerGrid, threadsPerBlock>>>(W,G,learning_rate);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Extraction de mu et sigma\n",
        "\n",
        "__global__\n",
        "void extract_mean_and_stddev_kernel(fmatrix X, fmatrix means, fmatrix sigmas) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col < X.cols) {\n",
        "        float sum = 0.0;\n",
        "        float sum_squares = 0.0;\n",
        "\n",
        "        // Calculer la somme et la somme des carrés des éléments dans la colonne\n",
        "        for (int row = 0; row < X.rows; ++row) {\n",
        "            float val = getfm(X, row, col);\n",
        "            sum += val;\n",
        "            sum_squares += val * val;\n",
        "        }\n",
        "\n",
        "        // Calculer la moyenne\n",
        "        float mean = sum / X.rows;\n",
        "        getfm(means, 0, col) = mean;\n",
        "\n",
        "        // Calculer l'écart-type (sigma)\n",
        "        float variance = sum_squares / X.rows - mean * mean;\n",
        "        float sigma = sqrtf(variance);\n",
        "        getfm(sigmas, 0, col) = sigma;\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Extract mus and sigmas from X columns */\n",
        "void extract_mean_and_stddev(fmatrix X, fmatrix means, fmatrix sigmas) {\n",
        "    assert(means.cols == X.cols);\n",
        "    assert(sigmas.cols == X.cols);\n",
        "    assert(means.rows == 1);\n",
        "    assert(sigmas.rows == 1);\n",
        "\n",
        "    int threadsPerBlock = X.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock - 1) / THREADS_PER_BLOCK + 1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "\n",
        "    extract_mean_and_stddev_kernel<<<blocksPerGrid, threadsPerBlock>>>(X, means, sigmas);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Standardisation de matrice\n",
        "\n",
        "__global__\n",
        "void standardize_matrix_kernel(fmatrix X, fmatrix means, fmatrix sigmas) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col > 0 && col < X.cols) {\n",
        "        // Récupérer la moyenne et l'écart-type de la colonne\n",
        "        float mean = getfm(means, 0, col);\n",
        "        float sigma = getfm(sigmas, 0, col);\n",
        "\n",
        "        // Normaliser chaque élément de la colonne\n",
        "        for (int row = 0; row < X.rows; ++row) {\n",
        "            float val = getfm(X, row, col);\n",
        "            getfm(X, row, col) = (val - mean) / sigma;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Standardize X */\n",
        "void standardize_matrix(fmatrix X, fmatrix means, fmatrix sigmas) {\n",
        "    assert(means.cols == X.cols);\n",
        "    assert(sigmas.cols == X.cols);\n",
        "    assert(means.rows == 1);\n",
        "    assert(sigmas.rows == 1);\n",
        "\n",
        "    int threadsPerBlock = X.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock - 1) / THREADS_PER_BLOCK + 1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "\n",
        "    standardize_matrix_kernel<<<blocksPerGrid, threadsPerBlock>>>(X, means, sigmas);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier_math.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G22rDKR3rv"
      },
      "source": [
        "## Evaluating Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7Vmzo72hpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c188d4-d541-4950-d0f9-13d30e9d9f92"
      },
      "source": [
        "%%writefile evaluate_accuracy.cuh\n",
        "\n",
        "/** Evaluate the accuracy of a linear classifier with D x M weight\n",
        " *  matrix W, using D x N input data X and M x N output labels Y.\n",
        " *  Z is a temporary matrix with dimensions M x N,\n",
        " *  which must be previously allocated.\n",
        " */\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z);\n",
        "\n",
        "/** Compute the logloss given M x N matrices of\n",
        " *  probabilities P and output labels Y\n",
        " *  and stores it in J.\n",
        " *  J is a matrix with dimensions 1 x 1,\n",
        " *  which must be previously allocated.\n",
        " *  logloss = sum_j -Y(j,k)*log(P(j,k))\n",
        " */\n",
        "float evaluate_logloss(fmatrix d_P, fmatrix d_Y);\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate_accuracy.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate_accuracy.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void evaluate_accuracy_kernel(fmatrix d_Y,fmatrix d_Z,int* count) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "        if (idx < d_Z.cols){\n",
        "        float z_max = getfm(d_Z,0,idx);\n",
        "        int i_max = 0;\n",
        "        for (int i = 1; i < d_Z.rows; ++i) {\n",
        "          if (getfm(d_Z,i,idx)>z_max) {\n",
        "                z_max = getfm(d_Z,i,idx);\n",
        "                i_max = i;\n",
        "          }\n",
        "        }\n",
        "      if (getfm(d_Y,i_max,idx)>=0.5) {\n",
        "          atomicAdd(count,1);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z) {\n",
        "    assert(d_Y.cols == d_Z.cols);\n",
        "    assert(d_Y.rows == d_Z.rows);\n",
        "    //printf(\"d_Y.cols: %d, d_Y.rows: %d, d_Z.cols: %d, d_Z.rows: %d\\n\",d_Y.cols,d_Y.rows,d_Z.cols,d_Z.rows);\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 1. compute Z = W^T X\n",
        "  // --> each column of Z corresponds to one input\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "  /*********************************\n",
        "  / TO BE COMPLETED\n",
        "  / ... compute Z = W^T X here ...\n",
        "  **********************************/\n",
        "\n",
        "  fmatrix_tmult(d_Z, 1.0, d_W, d_X);\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 2. For each column z of Z,\n",
        "  // find argmax_k z_k\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "  int true_class = 0;\n",
        "\n",
        "  int* d_count = 0;\n",
        "  gpuErrchk(cudaMalloc((void **)&d_count, sizeof(int)));\n",
        "  gpuErrchk(\n",
        "        cudaMemcpy( d_count, &true_class, sizeof(int), cudaMemcpyHostToDevice )\n",
        "  );\n",
        "\n",
        "    int threadsPerBlock = d_Z.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_accuracy_kernel<<< blocksPerGrid, threadsPerBlock >>>(d_Y,d_Z,d_count);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  gpuErrchk(\n",
        "          cudaMemcpy(&true_class, d_count, sizeof(int), cudaMemcpyDeviceToHost )\n",
        "  );\n",
        "\n",
        "  //printf(\"Correct results: %d out of %d\\n\",true_class,nb_tested);\n",
        "  //printf(\"Accuracy: %f\\n\",(float)true_class/(float)nb_tested);\n",
        "  return (float)true_class/(float)d_Z.cols;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void evaluate_logloss_kernel(fmatrix d_P, fmatrix d_Y, float* d_loss) {\n",
        "    int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (index < d_P.rows*d_P.cols) {\n",
        "        int row = index / d_P.cols;\n",
        "        int col = index % d_P.cols;\n",
        "        float p = getfm(d_P, row, col);\n",
        "        //printf(\"\\n%.5f\\n\", p);\n",
        "        float y = getfm(d_Y, row, col);\n",
        "        //printf(\"\\n%.5f\\n\", y);\n",
        "        float loss = 0.0;\n",
        "        if (p > 0 && p < 1) {\n",
        "           loss = -y * logf(p) - (1.0 - y) * logf(1.0 - p);\n",
        "        }\n",
        "        atomicAdd(d_loss, loss);\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_logloss(fmatrix d_P, fmatrix d_Y) {\n",
        "    assert(d_Y.cols == d_P.cols);\n",
        "    assert(d_Y.rows == d_P.rows);\n",
        "\n",
        "    float J = 0.0;\n",
        "    float* d_loss;\n",
        "    cudaMalloc(&d_loss, sizeof(float));\n",
        "    cudaMemset(d_loss, 0, sizeof(float)); // Initialize accumulator\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(d_P);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock - 1) / THREADS_PER_BLOCK + 1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_logloss_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_P, d_Y, d_loss);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "    // Copy the result back to host\n",
        "    cudaMemcpy(&J, d_loss, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    J /= fmatrix_elements(d_P); // Normalize the log loss by the number of elements\n",
        "    cudaFree(d_loss); // Clean up\n",
        "\n",
        "    return J;\n",
        "}\n"
      ],
      "metadata": {
        "id": "--50LgS9uzFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e425d8e9-7e8c-4a45-e140-2d74ba6f496b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate_accuracy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwZh8WULi_F"
      },
      "source": [
        "## Linear Classifier - Basic SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWO5p1NeHE9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbd3790-9328-4075-d777-f67d0408da77"
      },
      "source": [
        "%%writefile linear_classification.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train = 12000; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test = 5000; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"sample_data/california_housing_train.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 100;           // defeault: 10;\n",
        "    int periods = nb_iter;      // reporting period\n",
        "    int batch_size = N;         // defeault: N;\n",
        "    float learning_rate = 1e-4; // default: 1e-7\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(1.0,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    fmatrix d_Q = fmatrix_create_on_device(M, batch_size);\n",
        "    fmatrix d_Q_T = fmatrix_create_on_device(batch_size, M);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "    //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "    // Standarisation de X et Xtest\n",
        "    fmatrix d_X_T = fmatrix_create_on_device(N, D);\n",
        "    fmatrix d_Xtest_T = fmatrix_create_on_device(N_test, D);\n",
        "    fmatrix means = fmatrix_create_on_device(1, D);\n",
        "    fmatrix sigmas = fmatrix_create_on_device(1, D);\n",
        "\n",
        "    transpose(d_X_T, d_X);\n",
        "    transpose(d_Xtest_T, d_Xtest);\n",
        "    extract_mean_and_stddev(d_X_T, means, sigmas);\n",
        "    //printf(\"mu:\\n\");fmatrix_device_print(means);\n",
        "    //printf(\"sigma:\\n\");fmatrix_device_print(sigmas);\n",
        "    standardize_matrix(d_X_T, means, sigmas);\n",
        "    standardize_matrix(d_Xtest_T, means, sigmas);\n",
        "    transpose(d_X, d_X_T);\n",
        "    transpose(d_Xtest, d_Xtest_T);\n",
        "\n",
        "    //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "    // int batch_pointer = 0;\n",
        "    for (int i = 0; i < nb_iter; ++i ) {\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // compute Z = W^T X\n",
        "      // --> each column z of Z corresponds to one column x of X\n",
        "      ////////////////////////////////\n",
        "\n",
        "      fmatrix_tmult(d_Z,1.0,d_W,d_X);\n",
        "\n",
        "      ///////////////////////////////////\n",
        "      // TO BE COMPLETED\n",
        "      ///////////////////////////////////\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For each column z of Z, compute activation p(z);\n",
        "      // then update W\n",
        "      ////////////////////////////////\n",
        "\n",
        "      // compute softmax per column of Z and store in P\n",
        "      softmax_col(d_P, d_Z);\n",
        "\n",
        "      // evaluate logloss (for reporting only)\n",
        "      J = evaluate_logloss(d_P, d_Y);\n",
        "\n",
        "      // Q:=P-Y\n",
        "      fmatrix_sub(d_Q, d_P, d_Y);\n",
        "      //fmatrix_device_print(d_Q);\n",
        "\n",
        "      // compute gradient G = XQ^T\n",
        "      transpose(d_Q_T, d_Q);\n",
        "      //fmatrix_device_print(d_Q_T);\n",
        "      fmatrix_mult(d_G, 1.0, d_X, d_Q_T);\n",
        "      //fmatrix_device_print(d_G);\n",
        "\n",
        "      // ... possibly work with G here ...\n",
        "      // update weights W = W - learning_rate*G\n",
        "      fmatrix_update_weights(d_W, d_G, learning_rate);\n",
        "\n",
        "      ///////////////////////////////////\n",
        "      // TO BE COMPLETED\n",
        "      ///////////////////////////////////\n",
        "\n",
        "      //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "      //printf(\"Xtest:\\n\");fmatrix_device_print(d_Xtest);\n",
        "      //printf(\"Ytest:\\n\");fmatrix_device_print(d_Ytest);\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For reporting, compute logloss and accuracy\n",
        "      ////////////////////////////////\n",
        "      if (i%(nb_iter/periods)==0) {\n",
        "        float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "        printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
        "        fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "      }\n",
        "\n",
        "    }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "    fmatrix_free_on_device(&d_X_T);\n",
        "    fmatrix_free_on_device(&d_Xtest_T);\n",
        "    fmatrix_free_on_device(&means);\n",
        "    fmatrix_free_on_device(&sigmas);\n",
        "    fmatrix_free_on_device(&d_Q);\n",
        "    fmatrix_free_on_device(&d_Q_T);\n",
        "    fmatrix_free_on_device(&d_G);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing linear_classification.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "### Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z52xd0NMRKXb"
      },
      "source": [
        "!nvcc -o linclass_basic.out -Wno-deprecated-gpu-targets -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_vFkIT7fV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcce6623-177d-45bb-9175-421b5abb095c"
      },
      "source": [
        "%%time\n",
        "!./linclass_basic.out"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 17000 rows.\n",
            "Allocated memory for inputs: 17000 rows, 9 columns.\n",
            "Allocated memory for labels: 17000 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t-114.58\t-114.59\t-114.59\t-114.6\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t33.61\t34.83\t33.61\t34.83\t\n",
            "15\t19\t17\t14\t20\t29\t25\t41\t34\t46\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t2907\t812\t4789\t1497\t\n",
            "1283\t1901\t174\t337\t326\t236\t680\t168\t1175\t309\t\n",
            "1015\t1129\t333\t515\t624\t671\t1841\t375\t3134\t787\t\n",
            "472\t463\t117\t226\t262\t239\t633\t158\t1056\t271\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t2.6768\t1.7083\t2.1782\t2.1908\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.660200\n",
            "iter: 0, logloss: 0.880323, accuracy: 0.688600\n",
            "iter: 1, logloss: 0.499257, accuracy: 0.718400\n",
            "iter: 2, logloss: 0.420793, accuracy: 0.723600\n",
            "iter: 3, logloss: 0.384562, accuracy: 0.733000\n",
            "iter: 4, logloss: 0.367669, accuracy: 0.736400\n",
            "iter: 5, logloss: 0.356904, accuracy: 0.743600\n",
            "iter: 6, logloss: 0.349644, accuracy: 0.747600\n",
            "iter: 7, logloss: 0.344214, accuracy: 0.752000\n",
            "iter: 8, logloss: 0.339914, accuracy: 0.756200\n",
            "iter: 9, logloss: 0.336356, accuracy: 0.760600\n",
            "iter: 10, logloss: 0.333319, accuracy: 0.765000\n",
            "iter: 11, logloss: 0.330672, accuracy: 0.769000\n",
            "iter: 12, logloss: 0.328320, accuracy: 0.772200\n",
            "iter: 13, logloss: 0.326202, accuracy: 0.775000\n",
            "iter: 14, logloss: 0.324272, accuracy: 0.777800\n",
            "iter: 15, logloss: 0.322498, accuracy: 0.780800\n",
            "iter: 16, logloss: 0.320857, accuracy: 0.782600\n",
            "iter: 17, logloss: 0.319330, accuracy: 0.786400\n",
            "iter: 18, logloss: 0.317898, accuracy: 0.788600\n",
            "iter: 19, logloss: 0.316556, accuracy: 0.791400\n",
            "iter: 20, logloss: 0.315289, accuracy: 0.792600\n",
            "iter: 21, logloss: 0.314092, accuracy: 0.794000\n",
            "iter: 22, logloss: 0.312961, accuracy: 0.795400\n",
            "iter: 23, logloss: 0.311887, accuracy: 0.797600\n",
            "iter: 24, logloss: 0.310865, accuracy: 0.799400\n",
            "iter: 25, logloss: 0.309893, accuracy: 0.801600\n",
            "iter: 26, logloss: 0.308966, accuracy: 0.803400\n",
            "iter: 27, logloss: 0.308084, accuracy: 0.804400\n",
            "iter: 28, logloss: 0.307241, accuracy: 0.805800\n",
            "iter: 29, logloss: 0.306434, accuracy: 0.806400\n",
            "iter: 30, logloss: 0.305664, accuracy: 0.807000\n",
            "iter: 31, logloss: 0.304927, accuracy: 0.807600\n",
            "iter: 32, logloss: 0.304223, accuracy: 0.809200\n",
            "iter: 33, logloss: 0.303546, accuracy: 0.810400\n",
            "iter: 34, logloss: 0.302900, accuracy: 0.812000\n",
            "iter: 35, logloss: 0.302279, accuracy: 0.812400\n",
            "iter: 36, logloss: 0.301684, accuracy: 0.813600\n",
            "iter: 37, logloss: 0.301112, accuracy: 0.815200\n",
            "iter: 38, logloss: 0.300563, accuracy: 0.815600\n",
            "iter: 39, logloss: 0.300039, accuracy: 0.816800\n",
            "iter: 40, logloss: 0.299532, accuracy: 0.818800\n",
            "iter: 41, logloss: 0.299045, accuracy: 0.819800\n",
            "iter: 42, logloss: 0.298580, accuracy: 0.820600\n",
            "iter: 43, logloss: 0.298131, accuracy: 0.821600\n",
            "iter: 44, logloss: 0.297698, accuracy: 0.823000\n",
            "iter: 45, logloss: 0.297281, accuracy: 0.823800\n",
            "iter: 46, logloss: 0.296883, accuracy: 0.824600\n",
            "iter: 47, logloss: 0.296496, accuracy: 0.824600\n",
            "iter: 48, logloss: 0.296124, accuracy: 0.825800\n",
            "iter: 49, logloss: 0.295767, accuracy: 0.826600\n",
            "iter: 50, logloss: 0.295422, accuracy: 0.826600\n",
            "iter: 51, logloss: 0.295089, accuracy: 0.826600\n",
            "iter: 52, logloss: 0.294769, accuracy: 0.827600\n",
            "iter: 53, logloss: 0.294461, accuracy: 0.829200\n",
            "iter: 54, logloss: 0.294161, accuracy: 0.829400\n",
            "iter: 55, logloss: 0.293874, accuracy: 0.829200\n",
            "iter: 56, logloss: 0.293595, accuracy: 0.830200\n",
            "iter: 57, logloss: 0.293327, accuracy: 0.831000\n",
            "iter: 58, logloss: 0.293067, accuracy: 0.831600\n",
            "iter: 59, logloss: 0.292816, accuracy: 0.831800\n",
            "iter: 60, logloss: 0.292574, accuracy: 0.832400\n",
            "iter: 61, logloss: 0.292342, accuracy: 0.832400\n",
            "iter: 62, logloss: 0.292115, accuracy: 0.832400\n",
            "iter: 63, logloss: 0.291897, accuracy: 0.832800\n",
            "iter: 64, logloss: 0.291686, accuracy: 0.833200\n",
            "iter: 65, logloss: 0.291482, accuracy: 0.834400\n",
            "iter: 66, logloss: 0.291281, accuracy: 0.834600\n",
            "iter: 67, logloss: 0.291091, accuracy: 0.835600\n",
            "iter: 68, logloss: 0.290905, accuracy: 0.835800\n",
            "iter: 69, logloss: 0.290725, accuracy: 0.836000\n",
            "iter: 70, logloss: 0.290552, accuracy: 0.836000\n",
            "iter: 71, logloss: 0.290384, accuracy: 0.836400\n",
            "iter: 72, logloss: 0.290220, accuracy: 0.836400\n",
            "iter: 73, logloss: 0.290063, accuracy: 0.836400\n",
            "iter: 74, logloss: 0.289909, accuracy: 0.837200\n",
            "iter: 75, logloss: 0.289762, accuracy: 0.838000\n",
            "iter: 76, logloss: 0.289615, accuracy: 0.839000\n",
            "iter: 77, logloss: 0.289475, accuracy: 0.839000\n",
            "iter: 78, logloss: 0.289341, accuracy: 0.838800\n",
            "iter: 79, logloss: 0.289210, accuracy: 0.839000\n",
            "iter: 80, logloss: 0.289081, accuracy: 0.839000\n",
            "iter: 81, logloss: 0.288958, accuracy: 0.839200\n",
            "iter: 82, logloss: 0.288838, accuracy: 0.839600\n",
            "iter: 83, logloss: 0.288720, accuracy: 0.840000\n",
            "iter: 84, logloss: 0.288607, accuracy: 0.840200\n",
            "iter: 85, logloss: 0.288497, accuracy: 0.840400\n",
            "iter: 86, logloss: 0.288390, accuracy: 0.840400\n",
            "iter: 87, logloss: 0.288287, accuracy: 0.840800\n",
            "iter: 88, logloss: 0.288186, accuracy: 0.841400\n",
            "iter: 89, logloss: 0.288088, accuracy: 0.842000\n",
            "iter: 90, logloss: 0.287992, accuracy: 0.842400\n",
            "iter: 91, logloss: 0.287899, accuracy: 0.842800\n",
            "iter: 92, logloss: 0.287811, accuracy: 0.843600\n",
            "iter: 93, logloss: 0.287722, accuracy: 0.843400\n",
            "iter: 94, logloss: 0.287637, accuracy: 0.843200\n",
            "iter: 95, logloss: 0.287554, accuracy: 0.843200\n",
            "iter: 96, logloss: 0.287475, accuracy: 0.843400\n",
            "iter: 97, logloss: 0.287395, accuracy: 0.843200\n",
            "iter: 98, logloss: 0.287320, accuracy: 0.844400\n",
            "iter: 99, logloss: 0.287245, accuracy: 0.845000\n",
            "Duration (s): 0.354564\n",
            "final accuracy: 0.845000\n",
            "final weights: \n",
            "[\n",
            "-1.036937,\t1.178388;\n",
            "-0.496753,\t0.847434;\n",
            "-0.911904,\t0.977754;\n",
            "0.256459,\t-0.194075;\n",
            "-0.058310,\t-0.043152;\n",
            "0.487900,\t-0.423818;\n",
            "-1.029917,\t0.956460;\n",
            "0.805280,\t-0.281599;\n",
            "1.052310,\t-0.839437\n",
            "]\n",
            "CPU times: user 17 ms, sys: 1.81 ms, total: 18.8 ms\n",
            "Wall time: 909 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIyxh0ClrIz"
      },
      "source": [
        "Let's plot the logloss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR2kCNEIlpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "74982987-b3a0-4e1f-87fb-6698068dad2d"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "plt.legend(loc='lower center')\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.legend(loc='upper center')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Classifier - SGD with Mini-Batches"
      ],
      "metadata": {
        "id": "fo-LdsCBKnBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile linear_classification_mb.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train = 12000; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test = 5000; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"sample_data/california_housing_train.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log_mb.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 25;           // defeault: 10;\n",
        "    int periods = nb_iter;      // reporting period\n",
        "    int batch_size = 300;         // defeault: N;\n",
        "    float learning_rate = 1e-3; // default: 1e-7\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(1.0,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    fmatrix d_Q = fmatrix_create_on_device(M, batch_size);\n",
        "    fmatrix d_Q_T = fmatrix_create_on_device(batch_size, M);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "    //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "    // Standarisation de X et Xtest\n",
        "    fmatrix d_X_T = fmatrix_create_on_device(N, D);\n",
        "    fmatrix d_Xtest_T = fmatrix_create_on_device(N_test, D);\n",
        "    fmatrix means = fmatrix_create_on_device(1, D);\n",
        "    fmatrix sigmas = fmatrix_create_on_device(1, D);\n",
        "\n",
        "    transpose(d_X_T, d_X);\n",
        "    transpose(d_Xtest_T, d_Xtest);\n",
        "    extract_mean_and_stddev(d_X_T, means, sigmas);\n",
        "    //printf(\"mu:\\n\");fmatrix_device_print(means);\n",
        "    //printf(\"sigma:\\n\");fmatrix_device_print(sigmas);\n",
        "    standardize_matrix(d_X_T, means, sigmas);\n",
        "    standardize_matrix(d_Xtest_T, means, sigmas);\n",
        "    transpose(d_X, d_X_T);\n",
        "    transpose(d_Xtest, d_Xtest_T);\n",
        "\n",
        "    //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "    // int batch_pointer = 0;\n",
        "    for (int i = 0; i < nb_iter; ++i ) {\n",
        "          for (int batch_pointer = 0; batch_pointer < N / batch_size; ++batch_pointer) {\n",
        "              int startCol = batch_pointer * batch_size;\n",
        "              int endCol = startCol + batch_size;\n",
        "\n",
        "              fmatrix d_Xbatch = fmatrix_subcolumns(d_X, startCol, endCol);\n",
        "              fmatrix d_Ybatch = fmatrix_subcolumns(d_Y, startCol, endCol);\n",
        "\n",
        "              ////////////////////////////////\n",
        "              // compute Z = W^T X\n",
        "              // --> each column z of Z corresponds to one column x of X\n",
        "              ////////////////////////////////\n",
        "\n",
        "              fmatrix_tmult(d_Z,1.0,d_W,d_Xbatch);\n",
        "\n",
        "              ///////////////////////////////////\n",
        "              // TO BE COMPLETED\n",
        "              ///////////////////////////////////\n",
        "\n",
        "              ////////////////////////////////\n",
        "              // For each column z of Z, compute activation p(z);\n",
        "              // then update W\n",
        "              ////////////////////////////////\n",
        "\n",
        "              // compute softmax per column of Z and store in P\n",
        "              softmax_col(d_P, d_Z);\n",
        "\n",
        "              // evaluate logloss (for reporting only)\n",
        "              J = evaluate_logloss(d_P, d_Ybatch);\n",
        "\n",
        "              // Q:=P-Y\n",
        "              fmatrix_sub(d_Q, d_P, d_Ybatch);\n",
        "\n",
        "              // compute gradient G = XQ^T\n",
        "              transpose(d_Q_T, d_Q);\n",
        "              fmatrix_mult(d_G, 1.0, d_Xbatch, d_Q_T);\n",
        "\n",
        "              // ... possibly work with G here ...\n",
        "              // update weights W = W - learning_rate*G\n",
        "              fmatrix_update_weights(d_W, d_G, learning_rate);\n",
        "\n",
        "          }\n",
        "\n",
        "          //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "\n",
        "          ////////////////////////////////\n",
        "          // For reporting, compute logloss and accuracy\n",
        "          ////////////////////////////////\n",
        "          if (i%(nb_iter/periods)==0) {\n",
        "          float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "          printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
        "          fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "          }\n",
        "\n",
        "    }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "    fmatrix_free_on_device(&d_X_T);\n",
        "    fmatrix_free_on_device(&d_Xtest_T);\n",
        "    fmatrix_free_on_device(&means);\n",
        "    fmatrix_free_on_device(&sigmas);\n",
        "    fmatrix_free_on_device(&d_Q);\n",
        "    fmatrix_free_on_device(&d_Q_T);\n",
        "    fmatrix_free_on_device(&d_G);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ],
      "metadata": {
        "id": "F6VE0DqLKkO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148e9380-b554-4352-f782-7160a32ea472"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing linear_classification_mb.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling"
      ],
      "metadata": {
        "id": "MkNhTx8mUszN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o linclass_mb.out -Wno-deprecated-gpu-targets -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification_mb.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "metadata": {
        "id": "k88peXliUQBb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments"
      ],
      "metadata": {
        "id": "P8XhzGxvVCNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!./linclass_mb.out"
      ],
      "metadata": {
        "id": "1gHMssFUVMYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bc224c-4ffd-491b-e8e1-17c35245ab8a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 17000 rows.\n",
            "Allocated memory for inputs: 17000 rows, 9 columns.\n",
            "Allocated memory for labels: 17000 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t-114.58\t-114.59\t-114.59\t-114.6\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t33.61\t34.83\t33.61\t34.83\t\n",
            "15\t19\t17\t14\t20\t29\t25\t41\t34\t46\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t2907\t812\t4789\t1497\t\n",
            "1283\t1901\t174\t337\t326\t236\t680\t168\t1175\t309\t\n",
            "1015\t1129\t333\t515\t624\t671\t1841\t375\t3134\t787\t\n",
            "472\t463\t117\t226\t262\t239\t633\t158\t1056\t271\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t2.6768\t1.7083\t2.1782\t2.1908\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.660200\n",
            "iter: 0, logloss: 0.124869, accuracy: 0.727000\n",
            "iter: 1, logloss: 0.107046, accuracy: 0.745800\n",
            "iter: 2, logloss: 0.104375, accuracy: 0.761800\n",
            "iter: 3, logloss: 0.101876, accuracy: 0.775200\n",
            "iter: 4, logloss: 0.099904, accuracy: 0.786000\n",
            "iter: 5, logloss: 0.098329, accuracy: 0.791200\n",
            "iter: 6, logloss: 0.097061, accuracy: 0.796000\n",
            "iter: 7, logloss: 0.096037, accuracy: 0.801800\n",
            "iter: 8, logloss: 0.095212, accuracy: 0.804800\n",
            "iter: 9, logloss: 0.094549, accuracy: 0.808200\n",
            "iter: 10, logloss: 0.094016, accuracy: 0.812400\n",
            "iter: 11, logloss: 0.093591, accuracy: 0.814200\n",
            "iter: 12, logloss: 0.093253, accuracy: 0.814600\n",
            "iter: 13, logloss: 0.092984, accuracy: 0.815600\n",
            "iter: 14, logloss: 0.092772, accuracy: 0.816600\n",
            "iter: 15, logloss: 0.092606, accuracy: 0.818800\n",
            "iter: 16, logloss: 0.092476, accuracy: 0.818800\n",
            "iter: 17, logloss: 0.092377, accuracy: 0.819600\n",
            "iter: 18, logloss: 0.092302, accuracy: 0.819800\n",
            "iter: 19, logloss: 0.092246, accuracy: 0.820800\n",
            "iter: 20, logloss: 0.092206, accuracy: 0.821200\n",
            "iter: 21, logloss: 0.092178, accuracy: 0.821800\n",
            "iter: 22, logloss: 0.092160, accuracy: 0.822400\n",
            "iter: 23, logloss: 0.092150, accuracy: 0.822800\n",
            "iter: 24, logloss: 0.092147, accuracy: 0.823200\n",
            "Duration (s): 0.202603\n",
            "final accuracy: 0.823200\n",
            "final weights: \n",
            "[\n",
            "-1.041648,\t1.183100;\n",
            "-0.552713,\t0.903395;\n",
            "-1.141454,\t1.207302;\n",
            "0.303387,\t-0.241003;\n",
            "0.121528,\t-0.222989;\n",
            "0.417892,\t-0.353810;\n",
            "-1.302193,\t1.228737;\n",
            "0.928129,\t-0.404451;\n",
            "1.028857,\t-0.815986\n",
            "]\n",
            "CPU times: user 11.3 ms, sys: 0 ns, total: 11.3 ms\n",
            "Wall time: 407 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the logloss and accuracy."
      ],
      "metadata": {
        "id": "NBF4u0tGVPa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log_mb.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "plt.legend(loc='lower center')\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.legend(loc='upper center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TD-ZWU94VXeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "357611dd-d9e0-46c8-828b-f6eaf8492ffb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results summary\n",
        "\n",
        "Basic SGD\n",
        "- final accuracy: 84.5%\n",
        "- runtime: 0.35s\n",
        "- 100 epochs\n",
        "- learning rate: 1e-4\n",
        "\n",
        "Mini-batch SGD\n",
        "- final accuracy: 82.3%\n",
        "- runtime: 0.20s\n",
        "- batch size: 300\n",
        "- 25 epochs\n",
        "- learning rate: 1e-3\n"
      ],
      "metadata": {
        "id": "6WEXHyvpQ-1O"
      }
    }
  ]
}